AIU创智部三面任务说明文档
文档作者：吴兴明
一.本地部署一个大模型
1.任务历程：
任务开始，直接就是打开B站，敲上本地部署大模型，于是开始下载ollama，在下载时非常缓慢，去询问豆包，得到了得到了使用迅雷下载的解决方案，果真好用。但是我下载了这么个玩意，总要搞清楚他是干嘛的，怎么用的。这时豆包又派上了用场（Ollama 是一个用于在本地计算机上运行、管理和与各种大型语言模型交互的强大工具）既然有那么多强大的模型，那么应该选择哪一个也应该搞清楚。首先我下载了deepseek-r1:7b模型，deepseak非常火爆，故我选择了它，他的推理能力极强，提问时尽量提出多步思考的复杂问题。随后得知gemma3:4b模型十分全面，生态极佳，通用聊天、写作、推理、编程，故也将其下载。最后下载了一个qwen2:7b，选择它是因为他对处理中文内容很强大。
2.操作：
下载好ollama后在终端输入ollama run gemma3:4b（选择自己想要的模型），可用ollama list查看已有模型，用ollama rm gemma3:4b（选择自己已有的模型）删除该模型
二.搭建自己的智能体
1.任务历程：
原本想用langchian作为框架与工具进行智能体的搭建，但是通过ai得知工作量后，打算在后面拿更充裕的时间来搭建智能体（目前脑子里已经有很多有意思的构思了）。但是为了完成这一伟大庄严的创制部面试，我在智谱清言进行简单的智能体搭建，只用进行描述就能搭建一个智能体（这个智能体也很有意思，定能对部长大大陈林峰的胃口）
2.智能体
感知：获取环境信息（用户输入、API数据、文件内容等）
决策：分析信息并制定行动计划
执行：调用工具、生成响应、完成任务
学习：从用户反馈中学习
	 知识库自动更新
	 性能自我优化
 	 错误模式识别
	 参数自动调优
三.跑通yolo
1.任务历程：
与前面一样，在跑yolo前我要先知道什么是yolo，他是一种目标检测算法，可以看一眼就识别出图中的事物。首先最简单的跑通他的方式就是识别一张图片，但是在运行过程中间，我的GPU罢工了，完全没有一点动静，所以我就暂时只使用CPU来跑通yolo。既然能识别图片，那么一个实时的视频也一定可以进行识别，于是就借助ai写了一个调用电脑摄像头来跑yolo的程序。
四. 做一个调用模型API，实现对话的网页
1.API（应用程序接口）
通过API（搬运工）来调用各个互联网“工厂”的功能，调用每个功能需要发出请求与得到响应（具有固定的格式：HTTP协议），API返回的是JSON数据
2.Streamlit应用结构
页面配置：标题、图标和布局
状态管理：使用会话状态保存对话历史，确保页面刷新或交互时对话历史不丢失
侧边栏配置：API模式选择，参数配置，对话管理
主界面：对话历史显示，用户输入处理，流式响应显示
五.使用AIGC工具生成图片/视频/音乐
直接使用即梦AI，描述所需图片，最后生成（我生成了陈林峰在奥运决赛上庆祝胜利的图片和扣杀的照片）
